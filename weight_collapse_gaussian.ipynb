{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d719d2a-3fd6-43c2-b9b3-a163e674e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')  # hide warnings\n",
    "\n",
    "# standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# modules from particles\n",
    "import particles  # core module\n",
    "from particles import distributions as dists  # where probability distributions are defined\n",
    "from particles import state_space_models as ssms  # where state-space models are defined\n",
    "from particles.collectors import Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aa2f827-4b83-4ede-922f-96dc0960ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CurseOfDimension(ssms.StateSpaceModel):\n",
    "    \"\"\" Bearings-only tracking SSM.\n",
    "\n",
    "    \"\"\"\n",
    "    default_params = {'dimension': 100,\n",
    "                      'sigmaX': 1,\n",
    "                      'sigmaY': 2**0.5,\n",
    "                      'x0': np.zeros(100)\n",
    "                     }\n",
    "\n",
    "    def PX0(self):\n",
    "        arr_px0 = [dists.Normal(loc=self.x0[i], scale=self.sigmaX) for i in range(self.dimension)]\n",
    "        return dists.IndepProd(*arr_px0)\n",
    "\n",
    "    def PX(self, t, xp):\n",
    "        arr_px = [dists.Normal(loc=xp[:,i], scale=self.sigmaX) for i in range(self.dimension)]\n",
    "        return dists.IndepProd(*arr_px)\n",
    "\n",
    "    def PY(self, t, xp, x):\n",
    "        arr_py = [dists.Normal(loc=x[:,i], scale=self.sigmaY) for i in range(self.dimension)]\n",
    "        return dists.IndepProd(*arr_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6431da-7ef6-472c-b9c8-f98063111346",
   "metadata": {},
   "source": [
    "## d= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b24d057-c7b0-4fa4-9a82-2ab9e3cfc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "d = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e037aa41-1b51-471e-b603-fc4e7fbb0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840 860 880 900 920 940 960 980 1000 \n",
      "1122.0564197089989 seconds for d=100 and N=1000 in Gaussian.\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "N = 1*1000\n",
    "maxW_d100_p1k_T50 = []\n",
    "ESS_d100_p1k_T50 = []\n",
    "\n",
    "for i in range(1000):\n",
    "    if i%20 == 0: print(i+20, end=' ')\n",
    "    \n",
    "    bear = CurseOfDimension(dimension=d)\n",
    "    x, y = bear.simulate(T)\n",
    "    \n",
    "    fk = ssms.Bootstrap(ssm=bear, data=y)\n",
    "    alg = particles.SMC(fk=fk, N=N, store_history=1)\n",
    "    alg.run()\n",
    "    \n",
    "    maxW_d100_p1k_T50.append(max(alg.hist.wgts[-1].W))\n",
    "    ESS_d100_p1k_T50.append(alg.hist.wgts[-1].ESS)\n",
    "    \n",
    "print(f'\\n{timer() - start_time} seconds for d={d} and N={N} in Gaussian.')\n",
    "\n",
    "# Save the weights\n",
    "np.savetxt('maxW_d100_p1k_T50.txt', maxW_d100_p1k_T50, delimiter=',')\n",
    "np.savetxt('ESS_d100_p1k_T50.txt', ESS_d100_p1k_T50, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f495a5-63fb-4290-8c6e-30138a084cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840 860 880 900 920 940 960 980 1000 \n",
      "4520.51316091395 seconds for d=100 and N=10000 in Gaussian.\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "N = 10*1000\n",
    "maxW_d100_p10k_T50 = []\n",
    "ESS_d100_p10k_T50 = []\n",
    "\n",
    "for i in range(1000):\n",
    "    if i%20 == 0: print(i+20, end=' ')\n",
    "    \n",
    "    bear = CurseOfDimension(dimension=d)\n",
    "    x, y = bear.simulate(T)\n",
    "    \n",
    "    fk = ssms.Bootstrap(ssm=bear, data=y)\n",
    "    alg = particles.SMC(fk=fk, N=N, store_history=1)\n",
    "    alg.run()\n",
    "    \n",
    "    maxW_d100_p10k_T50.append(max(alg.hist.wgts[-1].W))\n",
    "    ESS_d100_p10k_T50.append(alg.hist.wgts[-1].ESS)\n",
    "    \n",
    "print(f'\\n{timer() - start_time} seconds for d={d} and N={N} in Gaussian.')\n",
    "\n",
    "# Save the weights\n",
    "np.savetxt('maxW_d100_p10k_T50.txt', maxW_d100_p10k_T50, delimiter=',')\n",
    "np.savetxt('ESS_d100_p10k_T50.txt', ESS_d100_p10k_T50, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e656c9f-8236-43ed-8d36-6bab17d1c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 500 520 540 560 580 600 620 640 660 680 700 720 740 760 780 800 820 840 860 880 900 920 940 960 980 1000 \n",
      "42812.599436355056 seconds for d=100 and N=100000 in Gaussian.\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "\n",
    "N = 100*1000\n",
    "maxW_d100_p100k_T50 = []\n",
    "ESS_d100_p100k_T50 = []\n",
    "\n",
    "for i in range(1000):\n",
    "    if i%20 == 0: print(i+20, end=' ')\n",
    "    \n",
    "    bear = CurseOfDimension(dimension=d)\n",
    "    x, y = bear.simulate(T)\n",
    "    \n",
    "    fk = ssms.Bootstrap(ssm=bear, data=y)\n",
    "    alg = particles.SMC(fk=fk, N=N, store_history=1)\n",
    "    alg.run()\n",
    "    \n",
    "    maxW_d100_p100k_T50.append(max(alg.hist.wgts[-1].W))\n",
    "    ESS_d100_p100k_T50.append(alg.hist.wgts[-1].ESS)\n",
    "    \n",
    "print(f'\\n{timer() - start_time} seconds for d={d} and N={N} in Gaussian.')\n",
    "\n",
    "# Save the weights\n",
    "np.savetxt('maxW_d100_p100k_T50.txt', maxW_d100_p100k_T50, delimiter=',')\n",
    "np.savetxt('ESS_d100_p100k_T50.txt', ESS_d100_p100k_T50, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
